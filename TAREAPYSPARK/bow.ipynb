{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djmH9LcvqtCa",
        "outputId": "6d561e37-c8be-417b-f558-f420ff6642ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 41 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 58.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=57584c35d2053a1f02ec6c82e0accadc4c46f504154f1cd6c90b42bbfce44d53\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "conf = SparkConf().setAppName(\"appName\")\n",
        "sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "8_uO6PxX6YLa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "import re\n",
        "import string\n",
        "\n",
        "import math\n",
        "from pyspark.sql.functions import *"
      ],
      "metadata": {
        "id": "9OFtabM_6aTV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# bow.hs en pyspark"
      ],
      "metadata": {
        "id": "PubeHi9q6rHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_useless_data(row):\n",
        "    stop_words=[]\n",
        "    pattern1 = re.compile(\n",
        "        'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    )\n",
        "    pattern2 = re.compile('[,.\\\"!@#$%^&*(){}?/;`~:<>+=-]')\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "    row1 = row.lower()\n",
        "    row2 = pattern1.sub('', row1)\n",
        "    row3 = pattern2.sub('', row2)\n",
        "    tokens = row3.split()\n",
        "    row_no_punctuation = [w.translate(table) for w in tokens]\n",
        "    row_no_num = [w for w in row_no_punctuation if w.isalpha()]\n",
        "    row4 = [w for w in row_no_num if not w in stop_words]\n",
        "    row = ' '.join(row4)\n",
        "    return row "
      ],
      "metadata": {
        "id": "cNFnXDZa6v3G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = sc.textFile(\"/content/corpus.txt\")\n",
        "data.collect()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vywHTmKBCehg",
        "outputId": "722ef372-2ff8-4f33-b332-3d989e7c4b00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Zips this RDD with its element indices.',\n",
              " '',\n",
              " 'The ordering is first based on the partition index and then the ordering of items within each partition. So the first item in the first partition gets index 0, and the last item in the last partition receives the largest index.',\n",
              " '',\n",
              " 'This method needs to trigger a spark job when this RDD contains more than one partitions.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF"
      ],
      "metadata": {
        "id": "Sxp6CNpnEW1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = data.flatMap(lambda line: line.split('\\n')).map(lambda word: (word))\n",
        "data1 = data1.zipWithIndex()\n",
        "data2=data1.flatMap(lambda x: [((x[1] + 1,i)) for i in x[0].split('\\n')])\n",
        "data2 = data2.map(lambda x: (x[0], remove_useless_data(x[1])))\n",
        "map1=data2.flatMap(lambda x: [((x[0],i),1) for i in x[1].split()])\n",
        "reduce=map1.reduceByKey(lambda x,y:x+y)\n",
        "tf=reduce.map(lambda x: (x[0][1],(x[0][0],x[1])))\n",
        "tf.collect()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFV38-Ub7AkU",
        "outputId": "31d4b20d-4c26-4282-bd42-fa15baebdd6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'zips this rdd with its element indices'), (2, ''), (3, 'the ordering is first based on the partition index and then the ordering of items within each partition so the first item in the first partition gets index and the last item in the last partition receives the largest index'), (4, ''), (5, 'this method needs to trigger a spark job when this rdd contains more than one partitions')]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('zips', (1, 1)),\n",
              " ('rdd', (1, 1)),\n",
              " ('with', (1, 1)),\n",
              " ('its', (1, 1)),\n",
              " ('element', (1, 1)),\n",
              " ('the', (3, 8)),\n",
              " ('ordering', (3, 2)),\n",
              " ('first', (3, 3)),\n",
              " ('on', (3, 1)),\n",
              " ('index', (3, 3))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IDF"
      ],
      "metadata": {
        "id": "7S9UrEjcEZx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map3=reduce.map(lambda x: (x[0][1],(x[0][0],x[1],1)))\n",
        "lendata=data.count()\n",
        "map4=map3.map(lambda x:(x[0],x[1][2]))\n",
        "#Numero de terminos en el documento\n",
        "reduce2=map4.reduceByKey(lambda x,y:x+y)\n",
        "idf=reduce2.map(lambda x: (x[0],math.log10(lendata/x[1])))\n",
        "idf.collect()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt3LIa4L90iV",
        "outputId": "a546846b-d483-425b-c126-a4a7a13ef4f7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('this', 0.3979400086720376),\n",
              " ('indices', 0.6989700043360189),\n",
              " ('is', 0.6989700043360189),\n",
              " ('based', 0.6989700043360189),\n",
              " ('partition', 0.6989700043360189),\n",
              " ('of', 0.6989700043360189),\n",
              " ('items', 0.6989700043360189),\n",
              " ('item', 0.6989700043360189),\n",
              " ('in', 0.6989700043360189),\n",
              " ('last', 0.6989700043360189)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF"
      ],
      "metadata": {
        "id": "ONawDl3LEz1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd=tf.join(idf)\n",
        "tfidf=rdd.map(lambda x: (x[1][0][0],(x[0],x[1][0][1],x[1][1],x[1][0][1]*x[1][1]))).sortByKey()\n",
        "tfidf.collect()[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqenhSVME2E-",
        "outputId": "390e7550-5839-4bb9-e269-953b2001fd35"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, ('this', 1, 0.3979400086720376, 0.3979400086720376)),\n",
              " (1, ('indices', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (1, ('zips', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (1, ('rdd', 1, 0.3979400086720376, 0.3979400086720376)),\n",
              " (1, ('with', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (1, ('its', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (1, ('element', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (3, ('partition', 4, 0.6989700043360189, 2.7958800173440754)),\n",
              " (3, ('of', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (3, ('items', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (3, ('item', 2, 0.6989700043360189, 1.3979400086720377)),\n",
              " (3, ('in', 2, 0.6989700043360189, 1.3979400086720377)),\n",
              " (3, ('last', 2, 0.6989700043360189, 1.3979400086720377)),\n",
              " (3, ('the', 8, 0.6989700043360189, 5.591760034688151)),\n",
              " (3, ('first', 3, 0.6989700043360189, 2.0969100130080567)),\n",
              " (3, ('and', 2, 0.6989700043360189, 1.3979400086720377)),\n",
              " (3, ('then', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (3, ('each', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (3, ('gets', 1, 0.6989700043360189, 0.6989700043360189)),\n",
              " (3, ('receives', 1, 0.6989700043360189, 0.6989700043360189))]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}